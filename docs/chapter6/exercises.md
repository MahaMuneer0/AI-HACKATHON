# Exercises and Labs for Chapter 6

## Exercises

1.  **RL vs. Supervised Learning**: Explain the key differences between Reinforcement Learning and Supervised Learning. When would you choose RL over Supervised Learning for a robotic task?
2.  **Imitation Learning Limitations**: Discuss the "covariate shift" problem in imitation learning. How can this issue lead to performance degradation in a real robot system?
3.  **DRL in Robotics**: Provide an example of how Deep Reinforcement Learning has been successfully applied to a complex robotic task (e.g., robotic manipulation, locomotion). What were the advantages of using DRL in that specific case?

<h2>Labs</h2>

1.  **Simple Q-Learning Implementation**: Implement a basic Q-learning algorithm in Python for a small, grid-world environment. Train an agent to find a goal while avoiding obstacles. Visualize the learned Q-values or the agent's policy.
2.  **Behavioral Cloning**: Collect a small dataset of human demonstrations for a simple task (e.g., moving a virtual object to a target using a mouse). Train a simple neural network to mimic the human's actions based on the observed states. Evaluate the performance of the learned policy.